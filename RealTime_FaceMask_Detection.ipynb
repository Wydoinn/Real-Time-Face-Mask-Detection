{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Face Mask Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from imutils.video import VideoStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads pre-trained model and opencv's DNN module and our trained model\n",
    "txt_file_path =\"Face_Detector/deploy.prototxt\"\n",
    "caffemodel_weights_Path = \"Face_Detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "Pretrain_face_detection_Model = cv2.dnn.readNet(txt_file_path, caffemodel_weights_Path)\n",
    "\n",
    "# Our trained model for classification of mask and without mask\n",
    "cls_model = load_model(\"RESNET.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function for Displaying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for displaying results in a live video stream or from a video file\n",
    "def main_func(vid_path=''):\n",
    "        def Realtime_Detection_func(Video_frame, Pretrain_face_detection_Model,cls_model):\n",
    "            (height, width) = Video_frame.shape[:-1]\n",
    "            \n",
    "            Img_blob = cv2.dnn.blobFromImage(Video_frame, 1.0, (224, 224),(104.0, 177.0, 123.0))\n",
    "\n",
    "            # pass the blob through the network and obtain the face detections\n",
    "            Pretrain_face_detection_Model.setInput(Img_blob)\n",
    "            face_identify = Pretrain_face_detection_Model.forward()\n",
    "            print(face_identify.shape)\n",
    "\n",
    "            # initialize our list of faces, their corresponding locations, and the list of predictions from our face mask network\n",
    "            faces_in_frame_lst = []\n",
    "            faces_location_lst = []\n",
    "            model_preds_lst = []\n",
    "\n",
    "            for i in range(0, face_identify.shape[2]):\n",
    "                conf_value = face_identify[0, 0, i, 2]\n",
    "                \n",
    "                if conf_value > 0.6:\n",
    "                    Rectangle_box = face_identify[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                    \n",
    "                    (starting_PointX, starting_PointY, ending_PointX, ending_PointY) = Rectangle_box.astype(\"int\")\n",
    "                    (starting_PointX, starting_PointY) = (max(0, starting_PointX), max(0, starting_PointY))\n",
    "                    (ending_PointX, ending_PointY) = (min(width - 1, ending_PointX), min(height - 1, ending_PointY))\n",
    "                    \n",
    "                    face_detect = vid_frm[starting_PointY:ending_PointY, starting_PointX:ending_PointX]\n",
    "                    face_RGB = cv2.cvtColor(face_detect, cv2.COLOR_BGR2RGB)\n",
    "                    face_Resize = cv2.resize(face_RGB, (224, 224))\n",
    "                    face_to_array = img_to_array(face_Resize)\n",
    "                    face_rescale = preprocess_input(face_to_array)\n",
    "\n",
    "                    faces_in_frame_lst.append(face_rescale)\n",
    "                    faces_location_lst.append((starting_PointX, starting_PointY, ending_PointX, ending_PointY))\n",
    "\n",
    "            if len(faces_in_frame_lst) > 0:\n",
    "                faces_in_frame_lst = np.array(faces_in_frame_lst, dtype=\"float32\")\n",
    "                model_preds_lst = cls_model.predict(faces_in_frame_lst, batch_size=16)\n",
    "\n",
    "            return (model_preds_lst, faces_location_lst)\n",
    "        \n",
    "        # loop over the frames from the video stream\n",
    "        if vid_path:\n",
    "            print(\"[INFO] starting video stream...\")\n",
    "            vid_stm = cv2.VideoCapture(vid_path)\n",
    "        else:\n",
    "            print(\"[INFO] starting live stream...\")\n",
    "            vid_stm = VideoStream(src=0).start()\n",
    "            \n",
    "        while True:\n",
    "            #ret, vid_frm = vid_stm.read()\n",
    "            #vid_frm = imutils.resize(vid_frm) \n",
    "            \n",
    "            if vid_stm is None:\n",
    "                break\n",
    "\n",
    "            if vid_path:\n",
    "                ret, vid_frm = vid_stm.read()\n",
    "            else:\n",
    "                vid_frm = vid_stm.read()\n",
    "\n",
    "            if vid_frm is None:\n",
    "            # If the frame is not successfully read, it means the video stream has ended\n",
    "                break\n",
    "\n",
    "            vid_frm = imutils.resize(vid_frm)\n",
    "        \n",
    "            # Check if the resized frame is None (imutils error)\n",
    "            if vid_frm is None:\n",
    "                continue\n",
    "            \n",
    "            (model_preds_lst, faces_location_lst) = Realtime_Detection_func(vid_frm, Pretrain_face_detection_Model, cls_model)\n",
    "\n",
    "            for (pred,Rectangle_box) in zip(model_preds_lst, faces_location_lst):\n",
    "                (starting_PointX, starting_PointY, ending_PointX, ending_PointY) = Rectangle_box\n",
    "                (mask_img, NoMask_img) = pred\n",
    "\n",
    "                label = \"Mask Detected\" if mask_img > NoMask_img else \"No Mask Detected\"\n",
    "                color = (0, 255, 0) if label == \"Mask Detected\" else (0, 0, 255)\n",
    "\n",
    "                label = \"{}: {:.2f}%\".format(label, max(mask_img, NoMask_img) * 100)\n",
    "\n",
    "                cv2.putText(vid_frm, label, (starting_PointX, starting_PointY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "                cv2.rectangle(vid_frm, (starting_PointX, starting_PointY), (ending_PointX, ending_PointY), color, 2)\n",
    "\n",
    "            cv2.imshow(\"Video Frame\", vid_frm)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord(\"q\"):\n",
    "                if vid_path:\n",
    "                    vid_stm.release()\n",
    "                break\n",
    "\n",
    "        # do a bit of cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        if not vid_path:\n",
    "            vid_stm.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to quit the program\n",
    "def exit():\n",
    "    #window.destroy()\n",
    "    window.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Creating Tkinter Windoows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows users to either browse and select a video file for processing, initiate a live stream with options to exit the program.\n",
    "def main():\n",
    "    def browseFiles():\n",
    "        filename = filedialog.askopenfilename(\n",
    "                   initialdir=\"/\",\n",
    "                   title=\"Select a File\",\n",
    "                   filetypes=((\"Text files\", \"*.mp4\"), (\"All files\", \"*.*\"))\n",
    "                   )\n",
    "        label_file_explorer.configure(text=\"File Opened: \" + filename)\n",
    "        return filename\n",
    "    \n",
    "    # Create the root window\n",
    "    global window\n",
    "    window = Tk()\n",
    "    window.title('Face Mask Detection')\n",
    "    window.geometry(\"500x500\")\n",
    "    window.config(bg=\"#F3F4F6\")  # Set background color\n",
    "\n",
    "    # Create a label with custom font and color\n",
    "    label_file_explorer = Label(window,\n",
    "                                text=\"Face Mask Detection\",\n",
    "                                font=(\"Helvetica\", 16),\n",
    "                                fg=\"#34495E\",  # Text color\n",
    "                                bg=\"#F3F4F6\")  # Background color\n",
    "    \n",
    "    button_explore = Button(window,\n",
    "                            text = \"Browse Files\",\n",
    "                            command = browseFiles)\n",
    "\n",
    "    button_live_stream = Button(window,\n",
    "                                text=\"Live Stream\",\n",
    "                                font=(\"Helvetica\", 12),\n",
    "                                command=main_func,\n",
    "                                padx=10,\n",
    "                                pady=5,\n",
    "                                bg=\"#27AE60\",  # Green color\n",
    "                                fg=\"white\")\n",
    "\n",
    "    button_video_stream = Button(window,\n",
    "                                 text=\"Video Stream\",\n",
    "                                 font=(\"Helvetica\", 12),\n",
    "                                 command=lambda: main_func(browseFiles()),\n",
    "                                 padx=10,\n",
    "                                 pady=5,\n",
    "                                 bg=\"#E74C3C\",  # Red color\n",
    "                                 fg=\"white\")\n",
    "\n",
    "    button_exit = Button(window,\n",
    "                         text=\"Exit\",\n",
    "                         font=(\"Helvetica\", 12),\n",
    "                         command=exit,\n",
    "                         padx=10,\n",
    "                         pady=5,\n",
    "                         bg=\"#95A5A6\",  # Gray color\n",
    "                         fg=\"white\")\n",
    "\n",
    "    label_file_explorer.pack(pady=20)  # Add some space below the label\n",
    "    button_live_stream.pack()\n",
    "    button_video_stream.pack()\n",
    "    button_exit.pack()\n",
    "\n",
    "    window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ ==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
